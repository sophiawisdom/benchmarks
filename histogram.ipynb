{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "The input conditions for extension module bench_histogram have changed. Bumping to version 26 and re-building as bench_histogram_v26...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu118/bench_histogram/build.ninja...\n",
      "Building extension module bench_histogram_v26...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=bench_histogram_v26 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -arch=sm_89 --keep --keep-dir /workspace/benchmark/temp -std=c++17 -c /workspace/benchmark/cpp/bench_histogram.cu -o bench_histogram.cuda.o \n",
      "\u001b[31mFAILED: \u001b[0mbench_histogram.cuda.o \n",
      "/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=bench_histogram_v26 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -arch=sm_89 --keep --keep-dir /workspace/benchmark/temp -std=c++17 -c /workspace/benchmark/cpp/bench_histogram.cu -o bench_histogram.cuda.o \n",
      "/workspace/benchmark/cpp/bench_histogram.cu(13): error: \"template\" is not allowed\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(20): warning #607-D: this pragma must immediately precede a statement\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(31): warning #12-D: parsing restarts here after previous syntax error\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(33): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(54): warning #12-D: parsing restarts here after previous syntax error\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(55): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(76): warning #12-D: parsing restarts here after previous syntax error\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(77): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(78): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(79): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(80): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(81): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(82): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(84): error: expected an identifier\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(84): error: identifier \"bins\" is undefined\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(84): error: expected a \")\"\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(84): error: expected a \")\"\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(84): error: expected an identifier\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(84): error: expected an identifier\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(88): error: this declaration has no storage class or type specifier\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(88): error: declaration is incompatible with \"cudaError_t cudaGetDeviceProperties(cudaDeviceProp *, int)\"\n",
      "/usr/local/cuda/include/cuda_runtime_api.h(1659): here\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(88): error: too many initializer values\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(88): error: a value of type \"cudaDeviceProp *\" cannot be used to initialize an entity of type \"int\"\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(89): error: expected a declaration\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(5): warning #177-D: variable \"CACHE_SIZE\" was declared but never referenced\n",
      "\n",
      "/workspace/benchmark/cpp/bench_histogram.cu(6): warning #177-D: variable \"MAX_BIN_SIZE\" was declared but never referenced\n",
      "\n",
      "20 errors detected in the compilation of \"/workspace/benchmark/cpp/bench_histogram.cu\".\n",
      "[2/3] c++ -MMD -MF bench_histogram_entry.o.d -DTORCH_EXTENSION_NAME=bench_histogram_v26 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /workspace/benchmark/cpp/bench_histogram_entry.cpp -o bench_histogram_entry.o \n",
      "ninja: build stopped: subcommand failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'bench_histogram_v26'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1893\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   1892\u001b[0m     stdout_fileno \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1893\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1894\u001b[0m         command,\n\u001b[1;32m   1895\u001b[0m         stdout\u001b[39m=\u001b[39;49mstdout_fileno \u001b[39mif\u001b[39;49;00m verbose \u001b[39melse\u001b[39;49;00m subprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m   1896\u001b[0m         stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT,\n\u001b[1;32m   1897\u001b[0m         cwd\u001b[39m=\u001b[39;49mbuild_directory,\n\u001b[1;32m   1898\u001b[0m         check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1899\u001b[0m         env\u001b[39m=\u001b[39;49menv)\n\u001b[1;32m   1900\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1901\u001b[0m     \u001b[39m# Python 2 and 3 compatible way of getting the error object.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspace/benchmark/histogram.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/benchmark/histogram.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcpp_extension\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/benchmark/histogram.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatistics\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/benchmark/histogram.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m bench_histogram \u001b[39m=\u001b[39m load(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbench_histogram\u001b[39;49m\u001b[39m\"\u001b[39;49m, sources\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcpp/bench_histogram_entry.cpp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcpp/bench_histogram.cu\u001b[39;49m\u001b[39m\"\u001b[39;49m], extra_cuda_cflags\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m-arch=sm_89\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m--keep\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m--keep-dir\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m/workspace/benchmark/temp\u001b[39;49m\u001b[39m\"\u001b[39;49m], verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/benchmark/histogram.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(bench_histogram)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brunpod/workspace/benchmark/histogram.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1284\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(name,\n\u001b[1;32m   1193\u001b[0m          sources: Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m]],\n\u001b[1;32m   1194\u001b[0m          extra_cflags\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m          is_standalone\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1203\u001b[0m          keep_intermediates\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1204\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[39m    Loads a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39m        ...     verbose=True)\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m _jit_compile(\n\u001b[1;32m   1285\u001b[0m         name,\n\u001b[1;32m   1286\u001b[0m         [sources] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(sources, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m sources,\n\u001b[1;32m   1287\u001b[0m         extra_cflags,\n\u001b[1;32m   1288\u001b[0m         extra_cuda_cflags,\n\u001b[1;32m   1289\u001b[0m         extra_ldflags,\n\u001b[1;32m   1290\u001b[0m         extra_include_paths,\n\u001b[1;32m   1291\u001b[0m         build_directory \u001b[39mor\u001b[39;49;00m _get_build_directory(name, verbose),\n\u001b[1;32m   1292\u001b[0m         verbose,\n\u001b[1;32m   1293\u001b[0m         with_cuda,\n\u001b[1;32m   1294\u001b[0m         is_python_module,\n\u001b[1;32m   1295\u001b[0m         is_standalone,\n\u001b[1;32m   1296\u001b[0m         keep_intermediates\u001b[39m=\u001b[39;49mkeep_intermediates)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1509\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                 hipified_sources\u001b[39m.\u001b[39madd(hipify_result[s_abs][\u001b[39m\"\u001b[39m\u001b[39mhipified_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m s_abs \u001b[39min\u001b[39;00m hipify_result \u001b[39melse\u001b[39;00m s_abs)\n\u001b[1;32m   1507\u001b[0m             sources \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(hipified_sources)\n\u001b[0;32m-> 1509\u001b[0m         _write_ninja_file_and_build_library(\n\u001b[1;32m   1510\u001b[0m             name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1511\u001b[0m             sources\u001b[39m=\u001b[39;49msources,\n\u001b[1;32m   1512\u001b[0m             extra_cflags\u001b[39m=\u001b[39;49mextra_cflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1513\u001b[0m             extra_cuda_cflags\u001b[39m=\u001b[39;49mextra_cuda_cflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1514\u001b[0m             extra_ldflags\u001b[39m=\u001b[39;49mextra_ldflags \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1515\u001b[0m             extra_include_paths\u001b[39m=\u001b[39;49mextra_include_paths \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m   1516\u001b[0m             build_directory\u001b[39m=\u001b[39;49mbuild_directory,\n\u001b[1;32m   1517\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1518\u001b[0m             with_cuda\u001b[39m=\u001b[39;49mwith_cuda,\n\u001b[1;32m   1519\u001b[0m             is_standalone\u001b[39m=\u001b[39;49mis_standalone)\n\u001b[1;32m   1520\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1521\u001b[0m     baton\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1624\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m   1623\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBuilding extension module \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m-> 1624\u001b[0m _run_ninja_build(\n\u001b[1;32m   1625\u001b[0m     build_directory,\n\u001b[1;32m   1626\u001b[0m     verbose,\n\u001b[1;32m   1627\u001b[0m     error_prefix\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mError building extension \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1909\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   1907\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(error, \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m error\u001b[39m.\u001b[39moutput:  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1908\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mdecode(\u001b[39m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 1909\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(message) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'bench_histogram_v26'"
     ]
    }
   ],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "import statistics\n",
    "bench_histogram = load(name=\"bench_histogram\", sources=[\"cpp/bench_histogram_entry.cpp\", \"cpp/bench_histogram.cu\"], extra_cuda_cflags=[\"-arch=sm_89\", \"--keep\", \"--keep-dir\", \"/workspace/benchmark/temp\"], verbose=True)\n",
    "print(bench_histogram)\n",
    "\n",
    "import torch\n",
    "blocks = torch.cuda.get_device_properties(0).multi_processor_count\n",
    "outs = torch.zeros((1024*32), dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "for bins in (1, 2, 4, 8, 16, 32, 64, 128, 256):\n",
    "    for items_per_thread in (128, 256, 1024, 65536,):\n",
    "        for n_threads in (128,256):\n",
    "            clocks = []\n",
    "            for i in range(100):\n",
    "                outs.zero_()\n",
    "                result = bench_histogram.bench_histogram(outs, bins, items_per_thread, n_threads)\n",
    "                if result == 1:\n",
    "                    print(f\"No kernel for \")\n",
    "                    break\n",
    "\n",
    "                outs_list = [int(a) for a in outs[:(n_threads//32)*blocks].tolist()]\n",
    "                if outs_list.count(-1) != 0:\n",
    "                    print(f\"FOUND {outs_list.count(-1)} -1 VALUES!!!\")\n",
    "                    print(outs_list)\n",
    "                    raise AssertionError\n",
    "                elif outs_list.count(0) != 0:\n",
    "                    print(f\"FOUND {outs_list.count(0)} 0 VALUES\")\n",
    "                    print(outs_list)\n",
    "                    raise AssertionError\n",
    "\n",
    "                clocks.extend(outs_list)\n",
    "            if not clocks: continue\n",
    "            mean = int(statistics.mean(clocks))\n",
    "            print(f\"FOR {bins=}\\t{items_per_thread=}\\t{n_threads=}\\tcycles/item: {int(mean/items_per_thread/32)}\")\n",
    "            # print(f\"{outs_list[:100]}\")\n",
    "            # results[n_threads][f\"{op_name}_{dtype}_{strat}\"].append(mean)\n",
    "            if mean < 1000:\n",
    "                pass # print(\"\\n\\nTHIS OP AND DTYPE ARE PROBABLY EMPTY\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
